{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNoNyParDhuAjMQRb+C5TRs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 4-2. Channel이 3개일 때, 1-Layer의 Convolution 연산"],"metadata":{"id":"5hRl_MmVSqaW"}},{"cell_type":"markdown","source":["## Convolution 연산이란?"],"metadata":{"id":"dJKNryiQFsoZ"}},{"cell_type":"markdown","source":["kernel은 input의 channel 수만큼 존재하며, 이 kernel들이 하나의 filter를 구성합니다. 각 channel 수준에서 Convolution 2D 연산을 계속하면 channel 수만큼의 output이 생깁니다. 예를 들어 7 x 7 x 3의 input에 3x3의 kernel, stride 1인 Convolution 연산을 하면 5 x 5 x 3 output이 나옵니다. 3개의 output의 동일한 위치의 숫자를 더하고 거기에 1번 filter의 bias를 더하여 1번 filter의 5 x 5 feature map을 만들 수 있습니다. 즉 “(5 x 5) x 3”개의 칸에 같은 값(bias)이 더해져 feature map을 만듭니다."],"metadata":{"id":"pMlF1bN3F0XT"}},{"cell_type":"markdown","source":["### filter 1개로 feature map 1개를 만들 수 있습니다."],"metadata":{"id":"r1fIxTIJGIxY"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=17SfHDmORPCUSnG_tOuIWYtEUx_HDkVNJ\">\n","\n"," [Channel이 3개일 때, 1-Layer의 Convolution 연산]\n","\n","filter마다 이 과정을 반복합니다.\n","\n","filter는 feature extractor입니다. filter가 많을수록 여러 개의 feature map이 생기며 복잡하고 다양한 pattern을 찾을 수 있습니다.\n","\n"],"metadata":{"id":"i6W1BBRVGLWe"}},{"cell_type":"markdown","source":["### input의 channel 수와 feature map의 channel 수는 다르지만 filter의 개수와 feature map의 channel 수는 같습니다."],"metadata":{"id":"bDmkeBByYcd3"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1aXntWYgYdNM0yNpSHlPI6dNHUs4JkYlX\">\n","\n","[Channel이 3개일 때, 1-Layer의 Convolution 연산]\n","\n","\n","\n","\n"],"metadata":{"id":"mToiKFQjY5Z6"}},{"cell_type":"markdown","source":["### 여러 layer의 convolution 연산"],"metadata":{"id":"HoWo8NtMYzyS"}},{"cell_type":"markdown","source":["layer가 여러 개일 경우의 convolution 연산은 아래와 같이 이전 layer의 output이 다음 layer의 input이 되는 과정을 반복합니다.\n","\n","<img src=\"https://drive.google.com/uc?id=1s70nvFu6F4zw7fbEEtSjF43_jxU9DOWq\">\n","\n","[여러 layer의 convolution 연산]"],"metadata":{"id":"ZOqYcf0oZLlX"}},{"cell_type":"markdown","source":["# 4-3. Hyper-Parameter에 대한 고민 (Kernel size, Channel size, Stride)"],"metadata":{"id":"Qb9FK358SuJv"}},{"cell_type":"markdown","source":["Convolution 연산을 할 때, Hyper-Parameter에 대한 고민을 해야 합니다. 이번 스텝에서는 kernel size, channel size, stride에 대해 고민해 봅시다."],"metadata":{"id":"98wDwt-3cUWY"}},{"cell_type":"markdown","source":["## Kernel Size"],"metadata":{"id":"nwyw0LLccckq"}},{"cell_type":"markdown","source":["- Kernel size가 커질수록 연산을 통해 찾아야 하는 파라미터의 수가 증가하게 됩니다.\n","- Kernel size가 작아질수록 데이터에 존재하는 global feature보다 local feature에 집중하게 됩니다. 쉽게 표현하자면 큼직한 특징보다는 지엽적인 특징에 집중해서 패턴을 찾게 됩니다."],"metadata":{"id":"mufDmwUQc3Og"}},{"cell_type":"markdown","source":["## Channel size"],"metadata":{"id":"QnDVFZqTckuK"}},{"cell_type":"markdown","source":["- Filter의 channel size가 커질수록 convolution 연산을 통해서 더 다양한 패턴을 찾을 수 있습니다.\n","- 그러나 channel의 사이즈가 커짐에 따라서 연산으로 찾아야 하는 파라미터의 숫자가 증가하게 됩니다."],"metadata":{"id":"9hvtzxtJc_pV"}},{"cell_type":"markdown","source":["##  Stride"],"metadata":{"id":"XsGYlQz2cnSI"}},{"cell_type":"markdown","source":["- Stride 값이 커지면 데이터를 빠르게 훑고 지나가는 연산을 하게 됩니다.\n","- 따라서 지역적인 특징을 꼼꼼하게 살펴보아야 할 경우에는 stride값을 크게 하는 것이 좋지 않습니다."],"metadata":{"id":"G2c8EpRFdIt1"}},{"cell_type":"markdown","source":["안타깝게도 이러한 hyperparameter의 값을 어떻게 정하는 것이 최적이라는 규칙을 찾는 것은 매우 어려운 일입니다. 따라서 연구자는 시행착오를 스스로의 실습으로 해거나 AutoML과 같은 방법으로 hyperparameter를 스스로 tuning해야 합니다.\n","\n","AutoML은 머신러닝과 딥러닝을 적용할 때마다 반복적인 과정으로 발생하는 비효율적인 작업(하이퍼 파라미터 실험, 문제 적합한 architecture를 찾는 과정 등)을 최대한 자동화하여 생산성과 효율을 높이기 위하여 등장한 것으로, 현재 다양한 툴들이 개발되어 있습니다.\n","\n","일반적으로 해당 task에서 가장 좋은 성능을 보여주는 모델의 hyperparameter를 그대로 따라하는 경우가 많습니다."],"metadata":{"id":"xvM2nU8KdEEj"}},{"cell_type":"markdown","source":["# 4-4. 1x1 Convolution"],"metadata":{"id":"FIV58hZxSyHA"}},{"cell_type":"markdown","source":["Convolution 학습을 수행하는 layer를 사용해서 원하는 모델을 구성할 때는 Filter의 Channel 수를 직접 결정해야 합니다. 이전에 언급한 대로, 일반적으로는 좋은 성능을 보이는 논문에서의 구조를 그대로 따라하지만, 때로는 연구자가 직접 결정해주어야 합니다.\n","\n","channel size가 지나치게 크면 학습을 통해 찾아야 하는 파라미터 숫자가 증가하기 때문에 많은 연산 비용을 들여야만 합니다. 하지만 1x1 Convolution을 사용하면 연산량을 매우 쉽게 줄일 수 있습니다.\n","\n","<img src=\"https://drive.google.com/uc?id=1rFsXkXeBFFEx27xXwbY3cQxMR5kgJN4p\">\n","\n","[1x1 convolution]\n","\n","https://ai.stackexchange.com/questions/13692/when-should-i-use-3d-convolutions\n"],"metadata":{"id":"X2djlWTudkro"}},{"cell_type":"markdown","source":["때로는 feature map의 가로 세로 사이즈는 변화시키지 않고 channel size만 변형하고 싶을 때가 있습니다. 물론 padding을 통하여 가로 세로 사이즈에 대한 변경없이 channel size만 변경할 수 있지만 파라미터 숫자 증가에 따른 연산량 증가의 문제를 피할 수 없습니다. 이럴 때 1x1 convolution은 연산량의 문제를 회피하면서도 channel size를 원하는 대로 변경하는 데에 도움을 줍니다.\n","\n","좀더 자세한 내용은 뒷부분의 inception 모듈에 대한 내용(6번 노드)에서 자세하게 설명하도록 하겠습니다."],"metadata":{"id":"5sLtmDN3dmeV"}},{"cell_type":"markdown","source":["# 4-5. Transposed Convolution"],"metadata":{"id":"BSxIilhmS1-v"}},{"cell_type":"markdown","source":["## Transposed Convolution [Up-Convolution]"],"metadata":{"id":"mVHiYnuWeiQv"}},{"cell_type":"markdown","source":["Transposed Convolution은 Auto-Encoder 구조에서 입력 정보가 압축된 compressed representation을 다시 원래 입력 사이즈로 반환하기 위해 사용합니다. 정보를 축약하는 down-sampling이라는 표현과 반대로 up-sampling한다고 말하기도 합니다.\n","\n","\n","<img src=\"https://drive.google.com/uc?id=1TfwE75zH0ldpPhWOzz1bkeNkyazTKAmo\">\n","\n","[Transposed Convolution]\n","\n","https://hackernoon.com/autoencoders-deep-learning-bits-1-11731e200694"],"metadata":{"id":"SUnr3rjBetqF"}},{"cell_type":"markdown","source":["Low-resolution의 이미지를 high-resolution으로 바꾸는 역할도 할 수 있고, Pixel 별로 할당된 정답값을 맞추는 task인 semantic segmentation에서도 활용할 수 있습니다.\n","\n","<img src=\"https://drive.google.com/uc?id=13VmLMIPNmkFANrvwWC0C8UYKB22_nNlp\">\n","\n","[semantic segmentation]\n","\n","https://vladlen.info/publications/feature-space-optimization-for-semantic-video-segmentation/\n"],"metadata":{"id":"jvS2Z0vCe1Jv"}},{"cell_type":"markdown","source":["## Transposed Convolution 연산"],"metadata":{"id":"WYBEkAkkeuL8"}},{"cell_type":"markdown","source":["Transposed Convolution 연산 방법을 영상을 통해 확인해 보세요.\n","\n","- Input: 4 x 4\n","- kernel: 3 x 3\n","- Output: 6 x 6\n","- stride: 1\n","\n","<img src=\"https://drive.google.com/uc?id=1gGtCIpAn_uLVy0JF61F23r__Bfv6ZrjJ\">\n","\n","A Conv2DTranspose(출처: https://medium.com/apache-mxnet/transposed-convolutions-explained-with-ms-excel-52d13030c7e8 )\n","\n","\n","<img src=\"https://drive.google.com/uc?id=1q-MUuCwprtmSPMYE3GMad4hF5UVZ3c7X\">\n","\n","https://medium.com/apache-mxnet/transposed-convolutions-explained-with-ms-excel-52d13030c7e8\n"],"metadata":{"id":"6B42Z-_2e09l"}},{"cell_type":"markdown","source":["- Q1. 7x7x3 image의 데이터에 5x5x3의 필터 5개로 convolution 연산을 했을 때 feature map의 사이즈는 어떻게 되나요? (stride는 1) => 4*4\n","- Q2. 7x7x3 image의 데이터에 5x5x3의 필터 3개로 convolution 연산을 했을 때 feature map의 사이즈는 어떻게 되나요? (stride는 2) => 2*2*3\n","- Q3. 9x9x3 image의 데이터를 3x3xn의 필터 4개로 convolution 연산을 두 번 했을 때, 연산의 결과로 나온 최종 feature map의 사이즈는 어떻게 되나요? (stride는 처음에는 1, 두번째에는 2, n은 입력 데이터의 채널 수와 같습니다.) => 3*3*4\n"],"metadata":{"id":"pRRMYPmwjBSL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wg3mGNZ3RN_K"},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"Z7yeizFsFraU"},"execution_count":null,"outputs":[]}]}